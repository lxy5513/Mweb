# 根据NTU训练VideoPose 

## 目标： 得到25个关节点的3Dpose数据 

## 步骤： 
- 筛选数据集： 
    1. NTU视频中的单人部分
        两人的有26个：A50-A60 A106-A120
    2. 有3D标签的部分  
        302 samples in "NTU RGB+D" dataset and 532 samples in "NTURGB+D 120" dataset have missing or incomplete skeleton data
    3. 正确的标注部分 

- 整理数据集：
    1. 25个关节点
    2. 将每个视频的2D关节点、3D关节点一一对应起来  
    3. 设计训练集、测试集格式
        
        ```
        ‘VideoPath'
    
        '3D_joints' : N, 25, 3
        '2D_joints' : N, 25, 2   
        ```

- 先用监督学习方法训练  
    1. 数据预处理  
        `Remove global offset, but keep trajectory in first position`
    2. 损失函数设计 
    3. architecture 设计
    
- 研究相关超参数的设置 
    标准化长边1920

- 用MPJPE loss做评估  





数据处理 

处理NTU 25个关节点： 
joints_left = [5, 6, 7, 8, 13, 14, 15, 16, 22, 23]
joints_right = [9, 10, 11, 12, 17, 18, 19, 20, 24, 25 ]

kps_left = [5, 6, 7, 8, 13, 14, 15, 16, 22, 23]
kps_right = [9, 10, 11, 12, 17, 18, 19, 20, 24, 25 ]





```
import os  
import numpy as np
# 所有可用的视频
name = 'Actions_01-49.txt'
with open(name, 'rt') as f:
    data = f.readlines()

videoNames = []
for i in range(len(data)):
    item = data[i][:-1]
    if 'skeleton' not in item:
        continue
    videoNames.append(item)
directory = 'nturgb_skeletons0_17' 
dataInfo = []
for i in range(len(videoNames)):
    if i % 100 == 1:
        print(videoPath)
    DataDic = {}

    videoName = videoNames[i]
    videoPath = os.path.join(directory, videoName)
    with open(videoPath, 'rt') as f:
        videoInfo = f.readlines()
    # 获得一段视频的每帧数据
    VideoDate=[]
    for j in range(len(videoInfo)):
        item = videoInfo[j]
        if item == '25\n':
            frame_data = videoInfo[j+1:j+26]
            VideoDate.append(frame_data)

    joints_2d = []
    joints_3d = []
    for videoFrame in VideoDate:
        joint_2d = []
        joint_3d = []
        for item in videoFrame:
            info = item.split(' ')
            x_3d = float(info[0])
            y_3d = float(info[1])
            z_3d = float(info[2])
            x_2d = float(info[5])
            y_2d = float(info[6])
            coordinate_3D = [x_3d, y_3d, z_3d]
            coordinate_2D = [x_2d, y_2d]
            joint_2d.append(coordinate_2D)
            joint_3d.append(coordinate_3D)
        joints_2d.append(joint_2d)
        joints_3d.append(joint_3d)

    DataDic['VideoPath'] = videoPath
    DataDic['3D_joints'] = np.array(joints_3d)
    DataDic['2D_joints'] = np.array(joints_2d)
    dataInfo.append(DataDic)
    print(i/len(videoNames))

```

