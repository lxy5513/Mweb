# 问题 

## 一 
实际训练是以hip为（0，0，0）点的，但是处理视频结果分为三种情况：
1. 处理一整段视频，范围的3D结果坐标hip值都是(0,0,0) 
2. 每次30帧，向前逐帧推进，返回的3D坐标每次都取最后一帧， 最后得到的hip值是变化的 
3. 为什么官方的demo的hip值是可以变动的， 它也是处理一段视频得到的hip结果 
为什么？ 

原因：
1. demo用的model与我们用的model不一样 
2. demo的rotation都是与视频匹配的，我们选用的是特定的一个 
3. 其它原因 

<br>

## 二 
To just run this model in a real-time mode. You can do the following:

- Keep a running buffer of the past 150~300 frames' pose estimation output.
- After every K frames, run the network on this buffer to generate one output. (K can be 10, 20, 30, 50, up to the buffer size)   

但是NTU很多视频是一百帧左右

我的处理方法是，用50帧的队列去做动作预测，然后填充0进去至300帧。

<br> 

## 三
目前st-gcn都用的是2个人体做预测的，尽管一个人体全部都是0， 但这样是否不太好


 