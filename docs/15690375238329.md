# nvidia-smi Volatile GPU-Utilization explanation

`nvidia-smi -l`  will give the GPU usage every one second

It is a sampled measurement over a time period. For a given time period, it reports what percentage of time one or more GPU kernel(s) was active



ps:
        
    the number of cores in a 1080ti is 3854

     the number of cores in a TESLA V100 is 3854






GPU-Util is not intended to represent the GPU's total processing abilities

## шоишо║
It is a sampled measurement over a time period. For a given time period, it reports what percentage of time one or more GPU kernel(s) was active (i.e. running).

It doesn't tell you anything about 
**how many SMs were used,**
or **how "busy" the code was,**
or **what it was doing exactly,**
or **in what way it may have been using memory.**

The above claim(s) can be verified without too much difficulty using a microbenchmarking-type exercise (see below).

I don't know how to define the time period exactly, but since it is also overall just a sampled measurement (i.e. nvidia-smi reports one sampled measurement as often as you poll it) I don't think it should be that important for general usage or understanding of the tool. The time period is obviously short, and is not necessarily related to the polling interval, if one is specified, for nvidia-smi. It might be possible to uncover the sampling time period using microbenchmarking techniques also.

Also, the word "Volatile" does not pertain to this data item in nvidia-smi. You are misreading the output format.

Here's a trivial code that supports my claim:







## SM means Streaming Multiprocessor

    The CUDA architecture is built around a scalable array of multithreaded Streaming Multiprocessors (SMs). 
    When a CUDA program on the host CPU invokes a kernel grid, the blocks of the grid are enumerated and distributed to multiprocessors with available execution capacity. 
    The threads of a thread block execute concurrently on one multiprocessor, and multiple thread blocks can execute concurrently on one multiprocessor. 
    As thread blocks terminate, new blocks are launched on the vacated multiprocessors.

    Each SM contains 8 CUDA cores, 
    and at any one time they're executing a single warp of 32 threads - so it takes 4 clock cycles to issue a single instruction for the whole warp. 
    You can assume that threads in any given warp execute in lock-step,