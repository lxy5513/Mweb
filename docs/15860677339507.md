# Horovod 

基于TensorFlow分布式深度学习框架 

> 数据并行」方法在分布式训练上包含在多节点上并行分割数据和训练。在同步情况下，不同批次数据的梯度将在不同节点上分别进行计算，但在节点之间进行互相平均，以对每个节点中的模型副本应用一致化更新。 


1. 运行训练脚本的多个副本，每个副本：

a）读取数据块 ；b）将其输入模型；c）计算模型更新（梯度）

1. 计算这些副本梯度的均值

2. 更新模型

3. 重复 1a 步骤      



<br><br>

在TensorFlow上的实现：

标准分布式 TensorFlow 包使用==参数服务器==的方法来平均梯度。
在这种方法之下，每个进程都有一到两个角色：工作线程或参数服务器。
**工作线程**处理训练数据，计算梯度，并把它们传递到**参数服务器**上进行平均。