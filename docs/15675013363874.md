# Introduce 
一个分布式的流处理平台 

## 应用
1. 构造实时的流数据管道，可以在系统和应用之间可靠的获取数据（相当于message queue) 
2. 构建实时流式应用程序，对这些流数据进行转化或者影响 


## 概念
1. Kafka作为一个集群，运行在一台或多台服务器上 
2. 通过topic对存储的流数据进行分类 
3. 每条记录包含一个key,一个value,一个时间戳 

## 四个核心的API 
- producer API 允许一个应用程序发布一串流式的数据到一个或者多个kafka topic 
- consumer API 允许一个应用程序订阅一个或者多个topic,并且对发布给他们的流式数据进行处理 
- The Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
- The Connector API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。


## Topic
Topic
在Kafka中，消息是按Topic组织的.

- Partition:topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。
- Segment：partition物理上由多个segment组成
- offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中. partition中的每个消息都有一个连续的序列号叫做offset,用于partition

## partition
分区：

topic中的partition是一个并行的概念。 Kafka能够为一个消费者池提供顺序保证和负载平衡，是通过将topic中的partition分配给消费者组中的消费者来实现的， 以便每个分区由消费组中的一个消费者消耗。通过这样，我们能够确保消费者是该分区的唯一读者，并按顺序消费数据。 众多分区保证了多个消费者实例间的负载均衡。但请注意，消费者组中的消费者实例个数不能超过分区的数量。


## Consumer Group
    同样是逻辑上的概念，是Kafka实现**单播**和**广播**两种消息模型的手段。
    同一个topic的数据，会广播给不同的group；
    同一个group中的worker，只有一个worker能拿到这个数据。
    换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。
